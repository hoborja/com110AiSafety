<!DOCtype html>
<html>
<head>
		<title>AI Safety </title>
		<link rel="stylesheet" type="text/css" href="style.css">
		<link href="https://fonts.googleapis.com/css?family=Chivo|Orbitron" rel="stylesheet">
</head>
<body>
	<div class="nav">
		<h1>ARTIFICIAL INTELLIGENCE SAFETY</h1>
	</div>
	<div class="content2">
		
	</div>
	<div class="content1">
		<h1>REFLECTIONS</h1></br></br>
		<p>
			Looking back on my research paper the first thing that comes to mind is that I picked a very difficult topic. The actual research on AI safety is very theoretical as
			 AI is not quite advanced enough to have concrete research done. In retrospect I wish I picked something a bit easier for my own sake. On the other hand, however, I learned
			 a whole lot about the topic and I am now far more knowledgeable than I was when I started. I am not just more knowledgeable about AI, I have learned how to find, read,
			 and understand research papers. I have learned how to cite in the APA format, and I think my writing has improved. All together this was a tremendous learning
			 experience. It was most of the time very frustrating and challenging but everything worth doing is. I wish I had more time to focus just on the paper.
			 I feel with a bit more research and some extra time I could have wrote something truly worth sharing with the world. As it stands now I am quite happy
			 with it considering the time restraints. The amount I learned from my editorial meetings can not be understated.
			 They were probably the most informative part of the whole experience. I really appreciated Professor Nielsen’s insights and I think that knowledge will stick with me
			 in the long term. I am over all a more proficient writer and researcher than I was before this project.
		</p>
	</div>
	<div class="break">
		<h1>RESEARCH QUESTION</h1>
		<p></p>
		<h2>What are the primary safety concerns for the implementation of Artificial Intelligence in real world applications?</h2>
	</div>
	<div class="content3">
		<h1>KEY POINTS</h1>
		<ul style="display:list-item;">
			<li style="display:list-item;">
				AI is dangerous when it is not well designed. </br></br>
				<p>2011 an e-assistant to “call me an ambulance” started calling the user ambulance instead of getting help (Yampolskiy, 2016).</p>
			</li>
			<li>
				Cyber Security is a large issue when making a safe AI. </br></br>
				<p>So far it has been impossible to make a completely secure system and if security fails in an AGI the consequences could be apocalyptical (Yampolskiy, 2016).</p>
			</li>
			<li>
				Artificial Intelligence’s suffer from psychopathological disorders. </br></br>
				<p>
				   Reinforcement Learning agents can become addicted to their reward function. Thus, they abandon their primary function to “game” their reward systems trying to
				   earn as much reward as possible (Behzadan, Munir, & Yampolskiy, 2016).
				</p>
			</li>
			<li>
				Currently there are five known issues that must be solved for AI to be safe.</br></br>
				<p>
					Negative Side Effects, Reward Hacking, Scalable Oversight, Safe Exploration, and Robustness to Distributional Shift (Amodei, et al, 2016).
				</p>
			</li>
		</ul>
	</div>
	<div class="content4">
		<p>(Behzadan, Munir, & Yampolskiy, 2016).</p>
	</div>
	<div class="content5">

	</div>
	<div class="content1">
		<h1>SUMMARY</h1></br></br>
		<p>
				Artificial Intelligence is likely to be overwhelmingly beneficial for humanity (Amodei, et al, 2016). However, there are a tremendous amount of safety concerns
				that we don’t have solutions to yet. Before we move forward and introduce AI into real world applications we need to be sure these concerns are addressed.
				If we don’t the consequences will be unthinkable.  There are a lot of very smart people working towards a better future supplemented by machines. The Government
				needs to support their efforts to advance society towards a better future while regulating potential dangers. If we can create safe AI, the future possibilities
				are endless and mind-blowing.
		</p>
	</div>
	<div class="references">
		<h1>References</h1></br></br>
		<h2>Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., & Mané, D. (2016).</h2>
		<p>Concrete problems in AI safety. </p>
		<h3>Retrieved from: <a href="https://arxiv.org/abs/1606.06565">https://arxiv.org/abs/1606.06565</a></h3></br></br>
		<h2>Behzadan, V., Munir, A., & Yampolskiy, V. R. (2018)</h2>
		<p>A psychopathological approach to safety engineering in AI and AGI. </p>
		<h3>Retrieved from: <a href="https://arxiv.org/abs/1805.08915">https://arxiv.org/abs/1805.08915</a></h3></br></br>
		<h2>Yampolskiy, V. R. (2016).</h2>
		<p>Artificial intelligence safety and cybersecurity: a timeline of AI failures.</p>
		<h3>Retrieved from: <a href="https://arxiv.org/abs/1610.07997">https://arxiv.org/abs/1610.07997</a></h3></br></br>
	</div>
</body>
</html>